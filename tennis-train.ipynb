{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the third project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from collections import deque\n",
    "import datetime;\n",
    "\n",
    "import json\n",
    "config = json.load(open('config.json'))\n",
    "train = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Tennis.app\"`\n",
    "- **Windows** (x86): `\"path/to/Tennis_Windows_x86/Tennis.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Tennis_Windows_x86_64/Tennis.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Tennis_Linux/Tennis.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Tennis_Linux/Tennis.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Tennis.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Tennis.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"Tennis_Windows_x86_64/Tennis.exe\",no_graphics=train, seed = config['SEED']['environment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net. If an agent hits the ball over the net, it receives a reward of +0.1.  If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01.  Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -7.8029089  -1.5\n",
      " -0.          0.         -6.53731155  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=train)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"TAU\": 0.001,\n",
      "    \"LR_CRITIC\": 0.0001,\n",
      "    \"LR_ACTOR\": 0.0001,\n",
      "    \"GAMMA\": 0.99,\n",
      "    \"BUFFER_SIZE\": 400000,\n",
      "    \"BATCH_SIZE\": 256,\n",
      "    \"WEIGHT_DECAY\": 0.0,\n",
      "    \"noise\": {\n",
      "        \"sigma\": 0.01,\n",
      "        \"mu\": 0.0,\n",
      "        \"theta\": 0.15\n",
      "    },\n",
      "    \"SEED\": {\n",
      "        \"environment\": 10,\n",
      "        \"agent\": 42\n",
      "    },\n",
      "    \"model\": {\n",
      "        \"actor\": [\n",
      "            {\n",
      "                \"type\": \"Linear\",\n",
      "                \"size\": 8,\n",
      "                \"activation\": \"RELU\"\n",
      "            },\n",
      "            {\n",
      "                \"type\": \"batchnormalization\"\n",
      "            },\n",
      "            {\n",
      "                \"type\": \"Linear\",\n",
      "                \"size\": 64,\n",
      "                \"activation\": \"RELU\"\n",
      "            },\n",
      "            {\n",
      "                \"type\": \"Linear\",\n",
      "                \"size\": 64,\n",
      "                \"activation\": \"RELU\"\n",
      "            },\n",
      "            {\n",
      "                \"type\": \"Linear\",\n",
      "                \"size\": 4\n",
      "            }\n",
      "        ],\n",
      "        \"critic\": [\n",
      "            {\n",
      "                \"type\": \"Linear\",\n",
      "                \"size\": 8,\n",
      "                \"activation\": \"RELU\"\n",
      "            },\n",
      "            {\n",
      "                \"type\": \"batchnormalization\"\n",
      "            },\n",
      "            {\n",
      "                \"type\": \"Linear\",\n",
      "                \"size\": 64,\n",
      "                \"activation\": \"RELU\"\n",
      "            },\n",
      "            {\n",
      "                \"type\": \"Linear\",\n",
      "                \"size\": 64,\n",
      "                \"activation\": \"RELU\"\n",
      "            },\n",
      "            {\n",
      "                \"type\": \"dropout\",\n",
      "                \"probability\": 0.2\n",
      "            },\n",
      "            {\n",
      "                \"type\": \"Linear\",\n",
      "                \"size\": 1\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "Actor(\n",
      "  (fc1): Linear(in_features=24, out_features=256, bias=True)\n",
      "  (batch): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "Critic(\n",
      "  (fc1): Linear(in_features=24, out_features=256, bias=True)\n",
      "  (batch): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=258, out_features=128, bias=True)\n",
      "  (dropout): Dropout(p=0.001)\n",
      "  (fc3): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from agent_ddpg import Agent\n",
    "agents = []\n",
    "print(json.dumps(config, indent=4))\n",
    "agents.append(Agent(state_size, action_size, config['SEED']['agent']))\n",
    "agents.append(Agent(state_size, action_size, config['SEED']['agent']))\n",
    "print(agents[0].actor_local)\n",
    "print(agents[0].critic_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Format specifier missing precision",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-75e4e98aed9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mgame_length_window\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mavg_game_length\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame_length_window\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Score (max over agents) from episode\\t{}:\\t{:.f}\\tAverage Score:\\t{:.4f}\\ttime:\\t{:s}\\tactions:\\t{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepisode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mep_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msolved_episode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mavg_score\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mexpected_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Solved in episode '\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mepisode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Format specifier missing precision"
     ]
    }
   ],
   "source": [
    "episodes = 1500\n",
    "expected_score = 0.5\n",
    "scores = []\n",
    "scores_window = deque(maxlen=100)\n",
    "avg_scores = []\n",
    "solved_episode = -1\n",
    "game_length_window =deque(maxlen=100)\n",
    "game_length = []\n",
    "avg_game_length = []\n",
    "network_loss = []\n",
    "for episode in range(1, episodes+1):                                    # play game for n episodes\n",
    "    start = datetime.datetime.now()\n",
    "    env_info = env.reset(train_mode=True)[brain_name]     # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    ep_scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    count = 0\n",
    "    [agent.reset() for agent in agents]\n",
    "    while True:        \n",
    "        count += 1\n",
    "        actions = [agents[i].act(states[i], True) for i in range(num_agents)] # select an action (for each agent)\n",
    "        actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        ep_scores += env_info.rewards                         # update the score (for each agent)\n",
    "        \n",
    "        [agents[i].step(states[i], actions[i], rewards[i], next_states[i], dones[i]) for i in range(num_agents)]\n",
    "        \n",
    "        [network_loss.append(agent.step_learn()) for agent in agents]\n",
    "        \n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "    #print(ep_scores)\n",
    "    \n",
    "    took = datetime.datetime.now() -start    \n",
    "    ep_score = np.max(ep_scores)\n",
    "    scores.append(ep_score)\n",
    "    scores_window.append(ep_score)\n",
    "    avg_score = np.mean(scores_window)\n",
    "    avg_scores.append(avg_score)    \n",
    "    game_length.append(count)\n",
    "    game_length_window.append(count)\n",
    "    avg_game_length.append(np.mean(game_length_window))\n",
    "    print('Score (max over agents) from episode\\t{}:\\t{:.5f}\\tAverage Score:\\t{:.5f}\\ttime:\\t{:s}\\tactions:\\t{}'.format(episode, ep_score, avg_score, str(took), count))\n",
    "    if (solved_episode < 0 and avg_score >= expected_score):\n",
    "        print('Solved in episode '+ episode)\n",
    "        solved_episode = episode\n",
    "        for i in range(num_agents):\n",
    "            torch.save(agent.actor_local.state_dict(), 'solved_{:d}_actor_local.pth'.format(episode))\n",
    "            torch.save(agent.critic_local.state_dict(), 'solved_{:d}_critic_local.pth'.format(episode))\n",
    "\n",
    "print('Solved in episode {}'.format(solved_episode))\n",
    "for i in range(num_agents):\n",
    "    torch.save(agents[i].actor_local.state_dict(), 'end_actor{}_local.pth'.format(i))\n",
    "    torch.save(agents[i].critic_local.state_dict(), 'end_critic{}_local.pth'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.plot(np.arange(len(avg_scores)), avg_scores)\n",
    "#plt.plot(np.arange(len(scores)), expected_score*np.ones(len(scores)))\n",
    "plt.xlabel('Episode number')\n",
    "plt.ylabel('Score')\n",
    "plt.show()\n",
    "plt.savefig('graph_trained_{:d}_episodes.png'.format(len(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(game_length)), game_length)\n",
    "plt.plot(np.arange(len(avg_game_length)), avg_game_length)\n",
    "#plt.plot(np.arange(len(scores)), expected_score*np.ones(len(scores)))\n",
    "plt.xlabel('Episode number')\n",
    "plt.ylabel('Turns')\n",
    "plt.show()\n",
    "plt.savefig('graph_gamelength_{:d}_episodes.png'.format(len(game_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(network_loss)), network_loss)\n",
    "#plt.plot(np.arange(len(scores)), expected_score*np.ones(len(scores)))\n",
    "plt.xlabel('Episode number')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "plt.savefig('graph_loss_{:d}_episodes.png'.format(len(network_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd2",
   "language": "python",
   "name": "drlnd2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
